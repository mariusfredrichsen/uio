# pylint: disable=missing-module-docstring
# pylint: disable=line-too-long
# pylint: disable=too-many-arguments

import mmap
from typing import Dict, List, Tuple, BinaryIO, Callable
from dataclasses import dataclass
from .trie import Trie
from .variablebytecodec import Buffer, VariableByteCodec


class TriePacker:
    """
    Packs a trie into a contiguous byte array. This yields a compact and memory-friendly data structure
    that can be easily persisted and memory-mapped by the operating system. For background details, see
    the paper "Tightly Packed Tries: How to Fit Large Models into Memory, and Make them Load Fast, Too"
    by Germann, Joanis, and Larkin.

    The current implementation is only meant for educational purposes and doesn't scale to large tries.
    A real-world implementation would be much more optimized. In particular, the construction of the
    contiguous byte array would not happen from an unpacked trie, but rather from a stream of (externally)
    sorted strings where the stream of strings would be sorted lexicographically except for that if string
    A is a prefix of string B then string B (the longest of the two) would appear before string A (the
    shortest of the two.) See, e.g., https://burntsushi.net/transducers/ for inspiration.

    The current implementation supports optional meta data associated with nodes, as long as these
    are positive integers. This could be extended to support more types (e.g., strings or floats) with
    type-specific compression strategies.

    TODO: Optimization opportunity: The majority of nodes have no meta data and are not final.
    """

    # File preamble for packed tries.
    _PREAMBLE = b"TPT"

    # The space in the header reserved for the byte offset to the packed trie's root node. Assume that
    # the stored offset will occupy no more than 5 bytes.
    _PLACEHOLDER = b"\x00\x00\x00\x00\x00"

    @dataclass
    class PackedCell:
        """
        Describes a logical (not actual) cell in the layout of the packed array. Corresponds to a
        single entry or line in Figure 1 (d) in the TPT paper. For testing and educational purposes
        only, to help "explain" the layout of the generated byte array.
        """
        offset: int                                 # The byte offset where this cell is stored.
        value: int | str | Tuple[int | None, bool]  # The value stored in this cell.
        description: str                            # A description of the cell.

    @dataclass
    class PackedNode:
        """
        Describes a trie node. Corresponds to a node in Figure 1 (b) in the TPT paper. Allows simple
        access to unpacked and uncompressed data, as backed by a packed node.
        """
        offset: int                      # The absolute byte offset where this node is stored.
        meta: None | int                 # The meta data associated with the node, if any.
        is_final: bool                   # True iff this node is a terminal node.
        children: List[Tuple[str, int]]  # The node's children, if any. Pairs of transition symbols and absolute byte offsets.

    def __init__(self):
        pass

    def pack(self, trie: Trie, filename: str, explain: bool = False) -> List[PackedCell] | None:
        """
        Persists a packed representation of the given trie to disk as a binary file.
        Optionally, an "explanation" of the binary file's logical layout can be returned
        back to the caller.
        """
        # Generate and return an "explanation" of the array layout? For simple testing
        # and pedagogical purposes.
        explanation: List[TriePacker.PackedCell] | None = [] if explain else None

        # Do a postorder traversal of the trie (non-recursively), using two stacks.
        # The second stack, when read in reverse order, yields the desired ordering.
        stack1: List[Tuple[Trie, str]] = [(trie, "")]
        stack2: List[Tuple[Trie, str]] = []

        while stack1:
            node, prefix = stack1.pop()
            for symbol in node.transitions():
                child = node.child(symbol)
                stack1.append((child, prefix + symbol))  # type: ignore[arg-type]
            stack2.append((node, prefix))

        # Maps a prefix to the byte offset where the corresponding packed node starts.
        # This mapping gets updated (and kept bounded in size) progressively as nodes
        # get written to disk, and the "backreferences" are required to be able to produce
        # relative offsets from a parent node to a child node. Since we write the nodes
        # in postorder traversal order, we can be sure that a node's children have been
        # written before the node itself.
        backreferences: Dict[str, int] = {}

        # Write the packed trie to disk.
        with open(filename, "wb") as file:
            offset = self._write_header(file)
            while stack2:
                node, prefix = stack2.pop()
                backreferences[prefix] = offset
                offset += self._write_node(file, node, prefix, offset, backreferences, explanation)
                for symbol in node.transitions():
                    del backreferences[prefix + symbol]

        # Sanity check. Only the root node should remain.
        assert len(backreferences) == 1 and "" in backreferences

        # Patch the file's header, now that we know the offset of the root node.
        with open(filename, "r+b") as file:
            self._patch_header(file, backreferences[""], explanation)

        return explanation

    def dump(self, filename: str, printer: Callable[[PackedNode], None]) -> None:
        """
        Reads a packed trie from disk and prints out a representation of each node.
        Nodes are printed in the order in which they occur in the named file.
        For simple testing and debugging purposes.
        """
        # Traverse the binary file, unpacking nodes as we traverse the data in
        # the order it was written. Demonstrate the use of memory-mapping per the
        # TPT paper.
        with open(filename, "r+b") as file:
            with mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ) as source:
                length = len(source)
                _, offset = TriePacker.read_header(source)
                while offset < length:
                    node, read = TriePacker.read_node(source, offset)
                    printer(node)
                    offset += read

    def _write_integer(self, file: BinaryIO, value: int) -> int:
        """
        Appends a compressed integer to the given file. Returns the number of bytes
        that were written.
        """
        buffer = bytearray()
        VariableByteCodec.encode(value, buffer)
        return file.write(buffer)

    @staticmethod
    def _read_integer(source: Buffer, offset: int) -> Tuple[int, int]:
        """
        Reads and decompresses an integer from the given buffer. Returns a pair
        comprised of the the decoded integer, and the number of bytes read from
        the source buffer.
        """
        return VariableByteCodec.decode(source, offset)

    def _write_node_value(self, file: BinaryIO, value: int | None, flag: bool) -> int:
        """
        Appends a compressed optional integer value to the given file, with some extra
        bits added. The extra bits encode the absence/presence of the integer, and
        a caller-supplied Boolean flag. Returns the number of bytes that were written.
        """
        assert value is None or (isinstance(value, int) and value >= 0)
        flag1 = flag
        flag2 = value is None
        flags = (flag1 << 1) | flag2
        value = 0 if value is None else value
        value = (value << 2) | flags
        return self._write_integer(file, value)

    @staticmethod
    def _read_node_value(source: Buffer, offset: int) -> Tuple[int | None, bool, int]:
        """
        Reads and decompresses an optional integer value (with some extra bits added)
        from the given source buffer. Returns a triple comprised of the the decoded
        integer (or None if absent), a Boolean flag, and the number of bytes read from
        the source buffer.
        """
        value, read = TriePacker._read_integer(source, offset)
        flags = value & 0b11
        flag1 = bool(flags & 0b10)  # The originally caller-supplied flag.
        flag2 = bool(flags & 0b01)  # Indicates if the value is really None or an integer.
        return (None if flag2 else (value >> 2), flag1, read)

    def _write_header(self, file: BinaryIO) -> int:
        """
        Write the file header. Returns the number of bytes that were written.
        """
        return file.write(self._PREAMBLE) + file.write(self._PLACEHOLDER)

    def _patch_header(self, file: BinaryIO, offset: int, explanation: None | List[PackedCell]) -> int:
        """
        Patch the header to reveal at which byte offset in the file
        the trie's root node is stored.
        """
        file.seek(len(self._PREAMBLE))
        if explanation is not None:
            explanation.insert(0, self.PackedCell(0, offset, "Offset of root node"))
        written = self._write_integer(file, offset)
        assert written <= len(self._PLACEHOLDER)
        return written

    @staticmethod
    def read_header(source: Buffer) -> Tuple[int, int]:
        """
        Skips the preamble, and reads the offset of the root node from the placeholder
        section in the header. Returns a pair comprised of the root offset, and the number
        of bytes (logically) read from the source buffer.
        """
        skipped = len(TriePacker._PREAMBLE)
        offset, _ = TriePacker._read_integer(source, skipped)
        return offset, skipped + len(TriePacker._PLACEHOLDER)

    def _write_node(self, file: BinaryIO, node: Trie, prefix: str, offset: int, backreferences: Dict[str, int], explanation: None | List[PackedCell]) -> int:
        """
        Writes all data for the given node to the given file, given the path to the node and the current
        byte offset into the file. Returns the number of bytes that were written.
        """
        buffer = bytearray()

        # Build the index table out from this node.
        for symbol in node.transitions():
            prefix2 = prefix + symbol
            VariableByteCodec.encode(ord(symbol), buffer)
            relative = backreferences[prefix] - backreferences[prefix2]
            VariableByteCodec.encode(relative, buffer)

        # Write the node meta data, the length of the index table, and the index table itself.
        written1 = self._write_node_value(file, node.get_meta(), node.is_final())
        written2 = self._write_integer(file, len(buffer))
        written3 = file.write(buffer)
        written4 = written1 + written2

        # Provide an explanation of the layout? For simplicity, rebuild the index table to get the offsets right.
        if explanation is not None:
            explanation.append(self.PackedCell(offset, (node.get_meta(), node.is_final()), f"Node value of '{prefix}' plus finality bit"))
            explanation.append(self.PackedCell(offset + written1, len(buffer), f"Size of index to child nodes of '{prefix}' in bytes"))
            buffer.clear()
            for symbol in node.transitions():
                prefix2 = prefix + symbol
                explanation.append(self.PackedCell(offset + written4 + len(buffer), symbol, f"Index key for '{prefix2}' coming from '{prefix}'"))
                VariableByteCodec.encode(ord(symbol), buffer)
                relative = offset - backreferences[prefix2]
                explanation.append(self.PackedCell(offset + written4 + len(buffer), relative, f"Relative offset of node '{prefix2}' ({offset} - {relative} = {backreferences[prefix2]})"))
                VariableByteCodec.encode(relative, buffer)

        return written1 + written2 + written3

    @staticmethod
    def read_node(source: Buffer, offset: int) -> Tuple[PackedNode, int]:
        """
        Reads all data for the given node. Returns the number of bytes that were read.
        """
        meta, is_final, read1 = TriePacker._read_node_value(source, offset)
        node = TriePacker.PackedNode(offset, meta, is_final, [])
        size, read2 = TriePacker._read_integer(source, offset + read1)
        read3 = 0
        while read3 < size:
            codepoint, read4 = TriePacker._read_integer(source, offset + read1 + read2 + read3)
            read3 += read4
            relative, read5 = TriePacker._read_integer(source, offset + read1 + read2 + read3)
            read3 += read5
            node.children.append((chr(codepoint), offset - relative))
        assert read3 == size
        return node, read1 + read2 + read3
